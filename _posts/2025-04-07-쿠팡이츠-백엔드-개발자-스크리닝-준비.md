---
title: "쿠팡 Senior Backend Engineering (Eats Customer) 스크리닝 준비"
categories:
  - junk1
toc: true
toc_sticky: true
---
  
### 💧 전직장 퇴사 이유?
> 저의 개발자로서의 강점은 현업과 소통하며 문제를 해결하고 팀과 협력하려는 과정에서 더 나은 결과를 도출해 낼 수 있다고 생각합니다.
> 하지만 전 직장에서는 독립적인 업무가 많아 기획자 및 개발자와 협력할 기회가 적어 제 강점을 충분히 발휘할 기회가 적었다고 생각합니다.
> 그래서 제 강점을 잘 활용하고 더 넓은 경험을 쌓을 수 있는 환경에서 성장하고 싶어 퇴사를 결심하였습니다.   
> 또한, 약 9년동안 한번도 쉬지 않고 계속 일을 해왔기 때문에 이번에는 잠시 휴식을 취하며 제 커리어와 앞으로의 방향을 차분히 고민할 시간을 가지려고 합니다.

1. 전 직장에서 독립적인 업무가 많았다고 하셨는데, 그렇다면 그곳에서 협력하는 기회가 전혀 없었나요? 혹시 협업을 강화하기 위한 노력을 하지 않으셨나요?
> 독립적인 업무가 많았다 하더라도, 팀 내에서 협업을 강화할 수 있는 방법을 찾을 수 있었다는 점을 언급하면서, 그럼에도 불구하고 지속적으로 협업이 부족했다고 느꼈던 이유를 설명할 수 있습니다. 예를 들어, 협업을 시도했으나 구조적으로나 문화적으로 협업이 어려웠다는 점을 부드럽게 설명하는 것이 중요합니다.

2. 그렇다면 협업의 기회를 늘리기 위해 어떤 방식으로 기획자나 개발자와 소통하려고 시도했나요? 예를 들어, 소통 채널을 더 적극적으로 활용했거나, 자주 미팅을 주도하려는 노력을 하지 않으셨나요?
> 이 질문에 대해서는 적극적으로 소통을 시도했으나, 그 시도가 원하는 결과를 얻지 못했다고 말할 수 있습니다. 예를 들어, "정기적인 미팅을 제안하거나, 의견을 나누기 위해 노력을 했지만, 조직의 업무 문화나 환경상 한계가 있었다"고 솔직하게 설명하고, 그럼에도 불구하고 협업의 중요성을 깨닫고 더 넓은 협업 환경에서 일하고자 결심했다는 점을 강조하는 것이 좋습니다.

3. 그럼에도 불구하고 퇴사 후 휴식을 취하고 싶다고 하셨는데, 이는 단순히 잠시 쉬고 싶다는 것 외에 향후 커리어 방향에 대해 어떤 고민이 있었던 건가요?
> "9년간의 지속적인 경력을 통해 많은 것을 배웠고, 이제는 좀 더 전략적으로 커리어를 계획하고 싶었습니다. 긴 시간 동안 일을 해왔기 때문에 잠시 쉬면서 제 자신의 업무 스타일과 방향성에 대해 다시 한번 고민하고 싶었고, 이를 통해 좀 더 발전할 수 있을 것이라 생각했습니다"라는 식으로 대답할 수 있습니다.   
> "저는 9년간 지속적으로 일을 해오면서 직무에 대한 전문성을 쌓았지만, 한편으로는 제 경력의 방향에 대해 깊이 고민해볼 시간이 필요했습니다. 그래서 퇴사 후 한동안 휴식을 취하며 제 커리어와 향후 방향에 대해 차분히 생각하고, 이를 바탕으로 제 경험을 더 잘 활용할 수 있는 직장을 찾고 있습니다."

---

### 💻 기술/프로젝트 관련 질문
1. Kafka를 활용한 메시징 시스템 개발 경험이 있다고 하셨는데, Kafka를 선택한 이유는 무엇이며, 설계 시 가장 중점을 둔 부분은 무엇이었나요?
> "Kafka는 회사에서 이미 사용하고 있어서 자연스럽게 사용하게 되었는데요, 그 안에서 운영 이슈를 직접 해결해보면서 많이 배울 수 있었습니다.
> 초반엔 shopNo % 파티션 수 방식으로 파티션을 할당했었는데, 특정 상점에서 메시지가 몰릴 경우 해당 파티션이 병목이 되어버리고, 같은 파티션을 공유하는 다른 상점들까지 소비가 느려지는 문제가 있었습니다.
> 이 문제를 해결하기 위해 라운드로빈 방식으로 파티션을 분산시키는 구조로 바꿨습니다. Kafka는 partition을 명시하지 않으면 내부적으로 순차적으로 파티션을 배정해주기 때문에, 기존 로직에서 shopNo 기반의 파티션 할당만 제거해주는 방식으로 쉽게 적용할 수 있었고요.
> 그리고 메시지 유실에 대비해서는 웹훅 알림을 통해 유실 메시지 내용을 바로 받을 수 있게 했고, 이 데이터를 다시 발행할 수 있는 관리자 기능을 개발해서 신뢰성을 보완했습니다.
> 운영 측면에선 SRE팀이 구축한 Grafana를 활용해 소비 속도나 장애 징후를 체크했고요. 이런 경험을 통해 Kafka의 구조나 운영 이슈 대응에 대해 실전에서 많이 익혔다고 생각합니다."

2. ClickHouse를 사용하여 대규모 데이터 분석을 하셨다고 했는데, ClickHouse와 기존 RDBMS(MySQL 등)의 차이를 어떻게 체감하셨고, 어떤 상황에서 ClickHouse가 특히 강점을 발휘한다고 느끼셨나요?
> ClickHouse는 단순한 읽기/쓰기보다는 집계성 데이터를 빠르게 조회할 수 있도록 설계된 DB라, 특히 통계 리포팅 쪽에서 효과가 컸습니다.
> 컬럼 기반 저장 구조라 필요한 컬럼만 읽는 식으로 작동하다 보니, 기존 RDBMS 대비 속도 면에서 훨씬 나았고요.
> 이전 회사에서 리포팅 페이지가 많은 구조였는데, MySQL 기반으로는 복잡한 집계 쿼리들이 느려서 사용자 경험에 영향을 주는 상황이 있었습니다.
> 저는 배치 스케줄러를 활용해서, 당일 데이터를 제외한 나머지는 미리 집계한 데이터를 ClickHouse에 적재하는 방식으로 개선 작업을 진행했고, 그 결과 응답 속도와 서버 부하 모두 개선되는 효과가 있었습니다.

🎯 1차 질문: ClickHouse를 실제 업무에 사용하셨다고 하셨는데, 당시 리포팅 성능 이슈는 구체적으로 어떤 상황에서 발생했나요?
> 통계데이터를 최대 13개월까지 한번에 보여줄수있었는데 (이전 회사는 따로 페이징이 없었고, 원페이지에 모든 데이터를 표현해야하는 사이트였습니다.)
> 많은 양의 일별, 주별, 월별 데이터를 한 페이지에 보여줘야하다보니깐 브라우저 메모리 이슈라든가, 페이지가 1분 이상 로딩되어 사용자에게 불편함을 주는 경우가 발생하였습니다.

🎯 2차 꼬리 질문: 그 이슈를 해결하기 위해 ClickHouse에 어떤 구조로 데이터를 적재했고, 배치 스케줄러는 어떤 방식으로 구성하셨나요?    
예를 들어 집계 주기, 스케줄링 도구, 쿼리 방식 같은 게 궁금합니다.
> 통계데이터의 특징을 활용하였습니다. 통계데이터는 당일자가 아니면 데이터가 변하거나 추가되는 경우가 있어서는 안됩니다.(사용자의 돈과 관련되어있기 떄문에)
> 그래서 당일자는 실시간으로 보여주되, 나머지 일자에 해당하는 데이터는 스케줄러를 통해서 clickhouse 미리 집계성 데이터를 만들어놔서 사용되도록하였습니다.
> 스케줄러는 사용자가 제일 사용량이 적은 매일 새벽에 돌아가도록 하였는데 
> 스케줄링 도구는 스프링 배치를 이용하였고 쿼리 방식은 기존 리포팅 페이지에 사용하던 쿼리를 그대로 사용하여 clickhouse에 재적재하는 방식으로 작업하였습니다.

🎯 3차 꼬리 질문: ClickHouse에 데이터를 재적재했다고 하셨는데, 혹시 중복 적재나 데이터 무결성 문제는 어떻게 방지하셨나요?    
예를 들어, 배치가 실패하거나 두 번 실행될 경우 문제가 생기지는 않았는지 궁금합니다.
> 그런 경우가 많이 발생하지 않았지만, 리포팅 페이지에서 해당 날짜에 해당하는 클릭하우스 데이터가 없는 경우 Rdbms(원본 데이터)에서 해당 날짜 데이터를 가져오도록 예외처리를 해놓았습니다.
> 그래서 만약 배치가 실패하거나 두번 실행되어 데이터 무결성문제가 발생하는 경우 클릭하우스에 적재된 문제된 데이터를 다 삭제하고 다시 배치를 수동으로 실행하는 방법으로 이슈를 해결하였습니다.

🎯 4차 꼬리 질문: RDBMS에서 데이터를 가져올 때 성능 이슈는 없었나요?   
예외 상황이라 하더라도 리포팅 페이지에서 느려지거나 장애로 이어지는 리스크는 없었는지, 그에 대한 대응은 어떻게 하셨는지도 궁금합니다.
> 맞습니다, 예외 상황에서는 실제로 리포팅 페이지가 느려질 수밖에 없었습니다.
> 이런 경우에는 빠르게 ClickHouse에 재적재를 진행하는 게 가장 현실적인 해결 방법이었고, 실제로 그런 상황이 발생하면 바로 수동으로 배치를 돌려서 사용자 불편을 최소화하려고 했습니다.
> 물론 장기적으로는 fallback 조회도 비동기적으로 처리하거나, 사용자에게 '데이터 갱신 중입니다' 같은 메시지를 보여주는 방식도 고려는 했는데, 당시엔 빠른 수동 재처리가 가장 효율적인 방법이었습니다.

🎯 5차 마지막 꼬리 질문: ClickHouse 적재 시 데이터 구조는 어떤 식으로 설계하셨나요?
예를 들어 날짜별 파티셔닝이나 MergeTree 엔진 등 어떤 설정을 활용하셨는지도 궁금합니다.
> ClickHouse에 집계성 데이터를 넣을 때는 리포팅 기준으로 자주 조회하는 컬럼 위주로 모델링했습니다.
> 엔진은 기본 MergeTree를 사용했고, shop_id, report_date 기준으로 ORDER BY 설정, 그리고 월 단위 toYYYYMM(report_date)로 파티셔닝해서 성능을 높였습니다.

TTL 설정은 따로 하지는 않았지만, 장기적으로는 13개월 넘은 데이터는 자동 삭제하도록 구성하는 것도 고려할 수 있다고 생각합니다.

3. 다양한 언어(PHP, Java, Kotlin, Python 등)를 사용해 오셨는데, 언어 선택 기준은 무엇이고, 팀 내에서 새로운 언어 도입 시 어떻게 의견을 조율하셨는지 궁금합니다.

4. 성능 개선을 위해 캐시 서버(Redis)를 도입하신 경험이 있다고 하셨는데, 어떤 문제를 해결하기 위해 캐시를 적용하셨고, 적용 후 실제로 어떤 변화가 있었는지 구체적으로 설명해주실 수 있나요?
