---
title: "쿠팡 Senior Backend Engineering (Eats Customer) 스크리닝 준비"
categories:
  - junk1
toc: true
toc_sticky: true
---

# 🎓 1분 자기소개
> 안녕하세요,   
> 저는 다양한 언어와 환경에서 빠르게 적응하고,   
> 기획자나 현업과의 소통을 통해 문제를 풀어가는 걸 좋아하는 백엔드 개발자 000 입니다.   
> 최근에는 Kafka 기반 메시징 시스템을 구축하면서 메시지 유실이나 병목 같은 문제를 해결했고,   
> ClickHouse나 Redis 같은 기술도 도입해서 대용량 데이터를 빠르게 처리하는 구조로 개선한 경험이 있습니다.   
> 기획이 완벽하지 않은 상태에서도 유연하게 방향을 잡아가며 프로젝트를 끝까지 책임지고 이끌어본 경험이 많고,   
> 그 과정에서 커뮤니케이션의 중요성을 더 많이 느껴왔습니다.
> 쿠팡이츠처럼 빠르게 성장하는 서비스에서, 저의 기술과 소통 역량이 더 잘 쓰일 수 있을 거란 기대에 지원하게 되었습니다. 감사합니다.

# ✅ 지원동기
> 전 직장에서 네고왕 이벤트를 진행하며, 순간 8만 명 이상이 몰리는 대규모 트래픽 상황을 경험했습니다.
> 그때 저는 넷퍼넬 도입을 담당했는데, 이 경험을 통해 대규모 트래픽을 어떻게 처리하는지에 대해 큰 호기심을 느꼈습니다.
> 쿠팡이츠는 빠르게 성장하고 있는 서비스이기도 하고, 제가 이전에 경험했던 것보다 훨씬 더 큰 트래픽을 다뤄볼 수 있는 환경이라고 생각했습니다.
> 대규모 시스템을 경험해보고 싶은 개인적인 욕심도 있고, 제가 가진 경험과 커뮤니케이션 역량을 쿠팡이츠 팀에 잘 녹여낼 수 있을 거라 판단해 지원하게 되었습니다.

---

# 💻 기술/프로젝트 관련 질문
## 1번 질문
Kafka를 활용한 메시징 시스템 개발 경험이 있다고 하셨는데, Kafka를 선택한 이유는 무엇이며, 설계 시 가장 중점을 둔 부분은 무엇이었나요?
> Kafka는 회사에서 이미 사용하고 있어서 자연스럽게 사용하게 되었는데요, 
> 그 안에서 운영 이슈를 직접 해결해보면서 많이 배울 수 있었습니다.
> 초반엔 shopNo % 파티션 수 방식으로 파티션을 할당했었는데, 특정 상점에서 메시지가 몰릴 경우 해당 파티션이 병목이 되어버리고, 
> 같은 파티션을 공유하는 다른 상점들까지 소비가 느려지는 문제가 있었습니다.
> 이 문제를 해결하기 위해 라운드로빈 방식으로 파티션을 분산시키는 구조로 바꿨습니다. 
> Kafka는 partition을 명시하지 않으면 내부적으로 순차적으로 파티션을 배정해주기 때문에, 
> 기존 로직에서 shopNo 기반의 파티션 할당만 제거해주는 방식으로 쉽게 적용할 수 있었고요.
> 그리고 메시지 유실에 대비해서는 웹훅 알림을 통해 유실 메시지 내용을 바로 받을 수 있게 했고, 
> 이 데이터를 다시 발행할 수 있는 관리자 기능을 개발해서 신뢰성을 보완했습니다.
> 운영 측면에선 SRE팀이 구축한 Grafana를 활용해 소비 속도나 장애 징후를 체크했고요. 
> 이런 경험을 통해 Kafka의 구조나 운영 이슈 대응에 대해 실전에서 많이 익혔다고 생각합니다.

### 🎯 1차 질문
Kafka에서 shopNo를 기준으로 파티션 할당했다고 하셨는데, 이 구조에서 어떤 병목 이슈가 발생했는지 구체적으로 설명해주실 수 있을까요?   
예를 들어, 어떤 상황에서 소비가 느려졌는지, 어떤 파티션이 병목이 되었는지 등.
> 상품이미지를 클라우드에 저장하는 방식을 카프카를 통해서 진행하였는데,
> 만약 특정 상점번호가 만개의 상품을 한번에 등록하는 경우 하나의 파티션에 만개 ~ 최소는 12만개 메세지가 발행되게 됩니다. 
> 이런 경우 그 파티션을 쓰는 다른 상점번호는 위 상점이 끝날때까지 상품이미지가 클라우드에 저장되지 않는 이슈가 발생되었습니다.

### 🎯 2차 Kafka 꼬리 질문
그 병목 문제를 해결하기 위해 라운드로빈 방식으로 변경하셨다고 했는데,   
이 구조로 바꾸면서 메시지 순서가 꼬이거나, 다른 부작용은 없었는지 궁금합니다.   
예를 들어, 같은 상점의 메시지가 서로 다른 파티션으로 들어가면 문제가 되지 않았나요?
> 상품을 새로 등록하는 경우에는 처리되는 순서에 의미가 없기 때문에 라운드로빈 방식이 적절하나,
> 상품이미지를 삭제하고 수정하는 경우에는 처리되는 순서가 의미가 있기 때문에 라운드로빈 방식이 적절하지 못하였습니다.
> 그래서 상품이미지를 "새로" 등록하는 경우에만 라운드로빈 방식을 적용하여 병목현상을 해결하였습니다.

### 🎯 3차 Kafka 꼬리 질문
그러면 상품 등록 메시지만 라운드로빈으로 발행하려면, 프로듀서 단에서 어떤 방식으로 구현하셨나요?   
파티션 번호를 아예 지정하지 않은 방식인지, 아니면 특정 로직으로 나눠서 보낸 건지 궁금합니다.
> 기본적으로는 shopNo % partition 수 로 파티션을 고정하는 구조였지만, 
> 상품 등록 메시지의 경우 순서가 중요하지 않아서 성능 병목을 줄이기 위해 파티션 번호를 명시하지 않는 방식으로 수정했습니다.
> Kafka에서는 프로듀서가 파티션을 명시하지 않으면, 기본적으로 라운드로빈 방식으로 파티션이 할당되기 때문에, 
> 등록 메시지에 대해서는 해당 부분의 코드를 주석 처리해서 라운드로빈 방식으로 전송되도록 했습니다.
> 반면 이미지 수정이나 삭제 같은 작업은 순서가 중요했기 때문에 기존의 shopNo 해시 기반 방식으로 유지했습니다.

### 🎯 4차 Kafka 꼬리 질문
메시지 유실 방지를 위해 관리자 기능도 개발하셨다고 하셨는데,   
어떤 기준으로 유실 여부를 판단했고, 어떻게 재발행할 수 있도록 구현하셨나요?
> 메세지 소비가 실패하는 경우 리트라이 토픽을 재발행해 실패되는 메세지가 없도록 작업해놓았습니다. 
> 메세지 소비가 완료되면 데이터베이스의 컬럼값을 완료로 업데이트 해주는데, 
> 스케줄러를 통해서 메세지는 발행됬는데 완료상태로 업데이트 되지 않는 값들을 웹훅 알림으로 받아 
> 관리자가 한꺼번에 다시 재발행할 수 있도록 기능을 작업해놓았습니다.

### 🎯 5차 Kafka 꼬리 질문
메시지 재발행 시 중복 처리 문제는 없었나요?   
예를 들어 이미 소비된 메시지를 다시 보내게 되면 같은 데이터가 두 번 처리될 수 있는데, 이건 어떻게 방지하셨나요?
> 중복 처리를 별도로 막지는 않았습니다.
> 해당 토픽은 상품 이미지를 클라우드에 업로드하는 용도인데, 
> 사용자가 중간에 이미지를 수정했을 가능성도 있기 때문에, 오히려 나중에 처리되는 메시지가 더 정확한 상태를 반영할 수 있다고 판단했습니다.
> 즉, 이 프로세스는 idempotent할 필요가 없었고, 설계상 중복 처리 허용이 가능한 구조였습니다

### 🎯 6차 추가 질문
Kafka 시스템에서 가장 힘들었던 장애 상황이나 트러블슈팅 경험이 있으셨나요?   
예를 들어 컨슈머 지연, 메시지 누락, 브로커 이슈 등…
> Kafka 사용 초기에 메시지 유실을 제대로 대비하지 못한 상태로 서비스가 배포되어, 상점 측에서 클레임이 많이 들어왔던 경험이 있습니다.
> 초기에는 유실된 메시지를 로그와 DB 상태를 보고 직접 수동으로 재프로듀싱해서 처리했는데, 반복적으로 이슈가 발생하다 보니 결국
> 스케줄러를 통해 유실된 데이터를 매일 새벽 자동 탐지하고
> 관리자 UI에서 유실 메시지를 수동 재발행할 수 있는 기능을 개발해
> 운영 리스크를 줄이는 구조로 개선했습니다.

### 🎯 7차 Kafka 꼬리 질문
그 유실된 메시지를 탐지하는 로직은 어떻게 구현하셨나요?   
예를 들어 어떤 기준으로 “아, 이건 유실됐다”고 판단하셨는지 궁금합니다.
> Kafka 메시지가 발행되면 관련 테이블의 컬럼 값을 ‘진행중’으로 바꾸고, 컨슈머가 처리를 완료하면 ‘완료’로 상태를 갱신하는 구조였습니다.
> 대부분의 메시지는 10초 이내에 처리되지만, 하루가 지나도 ‘진행중’ 상태로 남아있는 경우는 유실된 것으로 판단하였습니다.
> 이 상태를 매일 새벽 스케줄러에서 체크하고, 유실된 것으로 추정되는 레코드가 발견되면 웹훅 알림을 발송하여
> 관리자가 UI에서 직접 해당 데이터를 다시 프로듀싱할 수 있도록 했습니다.

### 🎯 8차 Kafka 꼬리 질문 (심화)
컨슈머가 메시지를 소비는 했는데, 처리 중 오류가 나서 DB 업데이트가 되지 않은 경우도 있을 것 같은데요.   
이런 경우에는 중복 발행이나 불일치 문제가 발생할 수 있는데, 이건 어떻게 처리하셨나요?
> Kafka offset은 커밋하지 않으면 다음 메시지 lag이 쌓여서 전체 처리가 멈춰버리는 문제가 있습니다.
> 그래서 저는 메시지를 컨슘한 뒤 로직 중간에 실패가 발생하더라도 offset은 커밋하도록 구성했고,
> 그 대신 실패한 메시지는 별도의 리트라이 토픽에 발행해서 후속 처리를 이어갈 수 있도록 했습니다.
> 이렇게 하면 전체 처리 흐름이 멈추지 않고, 실패한 메시지도 따로 추적 및 복구할 수 있어
> 운영 측면에서 안정성이 더 높았습니다.

### 🎯 9차 Kafka 꼬리 질문
그 리트라이 토픽은 몇 번까지 재시도하도록 설계하셨나요?   
혹시 무한 재시도로 인해 리소스 낭비가 발생할 수 있는 구조는 아니었나요?
> 초기에는 리트라이 토픽에 재시도 횟수 제한을 두지 않아 무한 재시도가 발생했고,
> 그 결과 리소스 낭비와 모니터링 부담이 생기는 문제가 있었습니다.
> 그래서 정책적으로 최대 3회까지만 재시도하도록 설정했고,
> 3회 이상 실패할 경우에는 별도 웹훅 알림을 통해 메신저로 이슈를 수신했습니다.
> 이후 알림을 보고  코드 로직 문제면 로직을 수정해 재배포하고,
> 상점 이미지 자체에 문제가 있는 경우라면 담당자와 협의해 수정 요청을 보냈습니다.
> 이렇게 자동 처리 + 수동 모니터링 체계를 조합해 운영 안정성을 확보했습니다.

### 🎯 10차 Kafka 꼬리 질문
그럼 리트라이 횟수는 어떻게 카운팅하셨나요?   
메시지 안에 필드를 넣어서 관리하셨는지, 아니면 외부 저장소(DB, Redis 등)를 쓰셨는지 궁금합니다.
> 리트라이 횟수는 Kafka 메시지 안에 retryCount 필드를 추가해서 관리했습니다.
> 컨슈머에서 메시지를 처리 실패 시, 해당 필드를 +1 해서 다시 리트라이 토픽에 발행했고,
> 3회를 초과하면 해당 메시지는 더 이상 재처리하지 않고 웹훅 알림을 통해 수동 모니터링 대상으로 분리했습니다.
> 리트라이 횟수는 메시지 자체에 포함되어 있기 때문에 외부 저장소 없이도 간단히 추적 가능했고,
> 처리 로직도 복잡해지지 않아 운영 안정성에 효과적이었습니다.

## 2번 질문
ClickHouse를 사용하여 대규모 데이터 분석을 하셨다고 했는데, ClickHouse와 기존 RDBMS(MySQL 등)의 차이를 어떻게 체감하셨고, 어떤 상황에서 ClickHouse가 특히 강점을 발휘한다고 느끼셨나요?
> ClickHouse는 단순한 읽기/쓰기보다는 집계성 데이터를 빠르게 조회할 수 있도록 설계된 DB라, 특히 통계 리포팅 쪽에서 효과가 컸습니다.
> 컬럼 기반 저장 구조라 필요한 컬럼만 읽는 식으로 작동하다 보니, 기존 RDBMS 대비 속도 면에서 훨씬 나았고요.
> 이전 회사에서 리포팅 페이지가 많은 구조였는데, MySQL 기반으로는 복잡한 집계 쿼리들이 느려서 사용자 경험에 영향을 주는 상황이 있었습니다.
> 저는 배치 스케줄러를 활용해서, 당일 데이터를 제외한 나머지는 미리 집계한 데이터를 ClickHouse에 적재하는 방식으로 개선 작업을 진행했고, 
> 그 결과 응답 속도와 서버 부하 모두 개선되는 효과가 있었습니다.

### 🎯 1차 질문
ClickHouse를 실제 업무에 사용하셨다고 하셨는데, 당시 리포팅 성능 이슈는 구체적으로 어떤 상황에서 발생했나요?
> 통계데이터를 최대 13개월까지 한번에 보여줄수있었는데 
> (이전 회사는 따로 페이징이 없었고, 원페이지에 모든 데이터를 표현해야하는 사이트였습니다.)
> 많은 양의 일별, 주별, 월별 데이터를 한 페이지에 보여줘야하다보니깐 브라우저 메모리 이슈라든가, 
> 페이지가 1분 이상 로딩되어 사용자에게 불편함을 주는 경우가 발생하였습니다.

### 🎯 2차 꼬리 질문
그 이슈를 해결하기 위해 ClickHouse에 어떤 구조로 데이터를 적재했고, 배치 스케줄러는 어떤 방식으로 구성하셨나요?    
예를 들어 집계 주기, 스케줄링 도구, 쿼리 방식 같은 게 궁금합니다.
> 통계데이터의 특징을 활용하였습니다. 통계데이터는 당일자가 아니면 데이터가 변하거나 추가되는 경우가 있어서는 안됩니다.(사용자의 돈과 관련되어있기 떄문에)
> 그래서 당일자는 실시간으로 보여주되, 나머지 일자에 해당하는 데이터는 스케줄러를 통해서 clickhouse 미리 집계성 데이터를 만들어놔서 사용되도록하였습니다.
> 스케줄러는 사용자가 제일 사용량이 적은 매일 새벽에 돌아가도록 하였는데 
> 스케줄링 도구는 스프링 배치를 이용하였고 쿼리 방식은 기존 리포팅 페이지에 사용하던 쿼리를 그대로 사용하여 clickhouse에 재적재하는 방식으로 작업하였습니다.

### 🎯 3차 꼬리 질문
ClickHouse에 데이터를 재적재했다고 하셨는데, 혹시 중복 적재나 데이터 무결성 문제는 어떻게 방지하셨나요?    
예를 들어, 배치가 실패하거나 두 번 실행될 경우 문제가 생기지는 않았는지 궁금합니다.
> 그런 경우가 많이 발생하지 않았지만, 리포팅 페이지에서 해당 날짜에 해당하는 클릭하우스 데이터가 없는 경우 
> Rdbms(원본 데이터)에서 해당 날짜 데이터를 가져오도록 예외처리를 해놓았습니다.
> 그래서 만약 배치가 실패하거나 두번 실행되어 데이터 무결성문제가 발생하는 경우 
> 클릭하우스에 적재된 문제된 데이터를 다 삭제하고 다시 배치를 수동으로 실행하는 방법으로 이슈를 해결하였습니다.

### 🎯 4차 꼬리 질문
RDBMS에서 데이터를 가져올 때 성능 이슈는 없었나요?   
예외 상황이라 하더라도 리포팅 페이지에서 느려지거나 장애로 이어지는 리스크는 없었는지, 그에 대한 대응은 어떻게 하셨는지도 궁금합니다.
> 맞습니다, 예외 상황에서는 실제로 리포팅 페이지가 느려질 수밖에 없었습니다.
> 이런 경우에는 빠르게 ClickHouse에 재적재를 진행하는 게 가장 현실적인 해결 방법이었고, 
> 실제로 그런 상황이 발생하면 바로 수동으로 배치를 돌려서 사용자 불편을 최소화하려고 했습니다.
> 물론 장기적으로는 fallback 조회도 비동기적으로 처리하거나, 
> 사용자에게 '데이터 갱신 중입니다' 같은 메시지를 보여주는 방식도 고려는 했는데, 
> 당시엔 빠른 수동 재처리가 가장 효율적인 방법이었습니다.

### 🎯 5차 마지막 꼬리 질문
ClickHouse 적재 시 데이터 구조는 어떤 식으로 설계하셨나요?
예를 들어 날짜별 파티셔닝이나 MergeTree 엔진 등 어떤 설정을 활용하셨는지도 궁금합니다.
> ClickHouse에 집계성 데이터를 넣을 때는 리포팅 기준으로 자주 조회하는 컬럼 위주로 모델링했습니다.
> 엔진은 기본 MergeTree를 사용했고, shop_id, report_date 기준으로 ORDER BY 설정, 그리고 월 단위 toYYYYMM(report_date)로 파티셔닝해서 성능을 높였습니다.
> TTL 설정은 따로 하지는 않았지만, 장기적으로는 13개월 넘은 데이터는 자동 삭제하도록 구성하는 것도 고려할 수 있다고 생각합니다.

## 3번 질문
다양한 언어(PHP, Java, Kotlin, Python 등)를 사용해 오셨는데, 언어 선택 기준은 무엇이고,    
팀 내에서 새로운 언어 도입 시 어떻게 의견을 조율하셨는지 궁금합니다.
> 다양한 언어는 회사의 기술 스택 또는 프로젝트 성격에 따라 자연스럽게 접하게 되었습니다. 
> 예를 들어, PHP는 기존 레거시 시스템 유지보수나 간단한 웹페이지 구축에, 
> Java나 Kotlin은 복잡한 백엔드 서비스에 적합해서 사용되었고, 
> Python은 데이터 처리나 배치 작업 등 유틸성 스크립트에 주로 활용되었습니다.
> 언어를 제가 직접 선택한 건 아니었지만, 새로운 언어나 프레임워크가 도입될 때마다 빠르게 적응하고, 
> 팀원들과 지식 공유를 통해 함께 성장할 수 있도록 노력했습니다. 
> 새로운 언어 도입에 있어서는 “우리 커리어에 도움이 될 뿐만 아니라, 
> 유지보수성과 개발 효율성 측면에서도 의미 있는 선택”이라는 점을 공감대로 만들려 노력했습니다.

## 4번 질문
성능 개선을 위해 캐시 서버(Redis)를 도입하신 경험이 있다고 하셨는데,   
어떤 문제를 해결하기 위해 캐시를 적용하셨고, 적용 후 실제로 어떤 변화가 있었는지 구체적으로 설명해주실 수 있나요?
> 통계 데이터를 시각화해주는 리포팅 페이지에서 성능 이슈가 심각했습니다.
> 예를 들어, 일/주/월 단위의 통계 데이터를 최대 13개월까지 한번에 불러오는 구조였고, 쿼리량이 많아 브라우저 로딩 속도가 1분 이상 걸리는 경우도 있었습니다. 
> 특히, 비즈니스적으로 사용자 경험이 중요한 페이지였기 때문에 속도 개선이 시급했습니다.
> ClickHouse를 도입하여 집계 성능 자체는 개선되었지만, 동일한 요청이 반복되는 경우가 많아 추가적으로 Redis를 도입해 자주 조회되는 통계 데이터를 캐싱하는 방식으로 접근했습니다.
> Redis에서는 요청 조건에 따라 생성된 응답 JSON을 key-value 형태로 저장했고, 
> key는 통계타입:기간:상점번호 등으로 구성해 캐시 구분이 명확하게 되도록 했습니다.
> 데이터 갱신은 두 가지 방식으로 처리했습니다.
> 당일 데이터는 실시간이기 때문에 캐시를 사용하지 않고 매번 조회
> 이전 날짜 데이터는 변경될 일이 없기 때문에 스케줄러를 통해 캐싱 후 일정 시간 또는 수동 갱신
> 결과적으로, 캐시를 도입한 후 1분 이상 걸리던 페이지 로딩 속도가 1초 이내로 감소했고, 클라이언트 및 비즈니스 측 피드백도 매우 긍정적이었습니다.
 
## 5번 질문
1분 이상 걸리던 쿼리를 2~3초로 줄이기 위해 어떤 방식의 튜닝을 했는지 설명해 주세요.
> 먼저 EXPLAIN 절을 활용해서 쿼리 실행 계획을 분석했습니다. 
> 여기서 WHERE 절 조건이 인덱스에 걸리는지 확인했고, 인덱스가 없는 컬럼일 경우 두 가지로 대응했습니다.
> 불필요한 조건을 제거하여 전체 범위 스캔을 줄였고, 해당 조건이 꼭 필요한 경우 인덱스를 추가하여 검색 속도를 높였습니다.
> 이 과정에서 전체 테이블 스캔(FULL TABLE SCAN)을 인덱스 기반 조회로 전환하는 것이 핵심이었고, 
> 실질적으로 쿼리 응답 속도를 수 초 내로 줄일 수 있었습니다.
 
### 🎯 1차 꼬리 질문
그렇게 인덱스를 추가하셨다고 했는데, 인덱스를 추가할 때 고려한 성능 트레이드오프나 부작용은 없었나요?
> 인덱스를 무조건 추가하기보다는, 해당 컬럼의 중복도와 활용도를 기준으로 판단했습니다.
> 중복도가 낮고 조회에 자주 활용되는 컬럼이라면 인덱스를 추가했지만,
> 중복도가 높거나 활용도가 낮은 경우엔 오히려 쓰기 성능 저하와 저장 공간 증가가 발생할 수 있어
> 다른 팀들과 협의하여 실제 사용처와 패턴을 확인한 뒤 결정했습니다.
> 만약 인덱스 추가가 어려운 상황이라면, ClickHouse나 Redis로 대체하여 조회 성능을 개선했습니다.

### 🎯 2차 꼬리 질문
> 회사에서 사용 스택으로 이미 도입된 부분도 있었지만, 사용하면서 자연스럽게 용도에 맞는 차이를 체감하게 되었습니다.
> ClickHouse는 대용량 로그, 집계성 쿼리 등 분석 위주의 데이터에 적합해 통계 처리나 리포팅용으로 사용했고,
> Redis는 빠른 응답이 필요한 실시간 캐싱이나 단건 조회에 적합해서 지연 민감한 서비스에 주로 활용했습니다.
> 이후에는 상황에 따라 두 시스템 중 적합한 쪽을 선택해 사용하게 되었습니다.

---

# 👥 협업/커뮤니케이션 관련 질문
## 1번 질문
기획자와의 소통을 통해 기술적인 한계를 설득하거나 다른 방향으로 설계한 경험이 많다"고 하셨는데,    
기술적 제약으로 인해 기획 방향을 바꿔야 했던 실제 사례와 그 과정에서 어떻게 소통했는지 자세히 말씀해주실 수 있나요?
> 사실 구체적인 사례가 오래돼서 하나하나 다 기억나진 않지만, 실무에서는 기획안이 기술적으로 그대로 구현되기 어려운 경우가 종종 있었습니다.
> 예를 들어, 리스트에서 다중 선택을 체크박스로 구현해달라는 요구가 있었는데, 실제 서비스 흐름상 단일 선택이 맞는 케이스라 라디오 버튼으로 대체하는 방향을 제안한 적이 있습니다.
> 이럴 땐 단순히 "안 된다"가 아니라, 왜 기술적으로 어렵거나 UX상 문제가 되는지, 그리고 대신 어떤 방식이 가능하며, 사용자 경험에는 어떤 영향이 있는지를 함께 설명드렸습니다.
> 기획자 분들과도 자주 회의를 하며 유저 입장과 시스템 제약을 같이 고민하는 방식으로 소통했기 때문에, 대부분 긍정적으로 수용해주셨고, 오히려 협업이 더 잘 이루어졌던 것 같습니다.

### 🎯 1차 꼬리 질문
그렇게 기획자와 협의해서 기획안을 조정한 후, 실제 사용자 반응이나 비즈니스 성과 측면에서 눈에 띄는 변화가 있었던 경험이 있을까요?   
예를 들어, 사용성이 더 좋아졌다거나, 클레임이 줄었다는 식으로요.
> 대표님의 지시로 성과관리 시스템을 개발한 경험이 있습니다. 
> 이 프로젝트는 사전에 완성된 기획서 없이 시작되었고, 개발을 진행하면서 기획자 및 대표님과 함께 기획을 구체화해 나가야 했습니다.
> 기술적으로는 광고주의 성과를 영업자, 어드민 별로 구분해서 볼 수 있는 구조로 설계했고, 
> 데이터 집계를 효율적으로 하기 위해 쿼리 최적화와 캐싱도 고려했습니다.
> 결과적으로 완성된 시스템을 통해 영업자 및 어드민이 각자의 KPI를 명확히 확인할 수 있었고, 
> 소진율이 낮은 광고주를 집중적으로 케어하는 데 큰 도움이 되었다고 피드백을 받았습니다. 
> 매출 향상에도 긍정적인 영향을 주었다고 들었습니다.

### 🎯 2차 꼬리 질문
해당 프로젝트처럼 기획과 개발이 병행되는 경우, 예상치 못한 요구사항이 많이 발생했을 것 같은데요.    
그럴 때 일정 관리나 우선순위 조율은 어떻게 하셨나요?
> 일정 관리는 우선 기획자와 함께 먼저 나온 주요 기능들을 중심으로 일정을 수립했습니다. 
> 이후 프로젝트를 진행하면서 추가적인 기획이 생기는 경우가 있었는데, 
> 이런 경우에는 우선순위를 다시 조율하거나, 1차 릴리즈 이후 추가 개발 항목으로 분리하는 방식으로 협의했습니다.
> 이렇게 하면 개발 일정에 큰 지장이 가지 않으면서도, 기획 변경 사항에 유연하게 대응할 수 있었습니다.

### 🎯 3차 꼬리 질문
기획자나 대표님과 우선순위를 조율할 때 의견이 충돌했던 경험이 있다면, 그때는 어떻게 해결하셨나요?
> 실무자 입장에서 판단한 우선순위와 대표님이 생각하시는 우선순위가 다르게 느껴지는 경우가 종종 있었습니다. 
> 이런 상황에서는 우선 저희가 판단한 기준과 이유를 최대한 논리적으로 설명드렸고, 
> 만약 대표님께서 납득하지 않으시면 경영적인 관점도 고려하여 대표님의 우선순위대로 개발을 진행했습니다.
> 물론 그로 인해 일정이 빠듯해져 야근을 하거나 리소스가 집중되는 상황도 있었지만, 
> 일단 프로젝트의 마무리와 데드라인을 지키는 것을 우선으로 생각하며 팀원들과 함께 책임감을 가지고 마무리했던 경험이 있습니다.

### 🎯 4차 꼬리 질문
이렇게 빠듯한 일정 속에서도 팀원들과 협업하며 프로젝트를 완수하셨다고 했는데, 그 과정에서 팀 내 역할 분담이나 커뮤니케이션은 어떻게 하셨나요?
> 해당 프로젝트의 개발 리드를 맡았기 때문에 전체 흐름과 구조를 가장 잘 알고 있었고, 
> 자연스럽게 핵심 기능이나 중요한 로직은 제가 직접 맡아서 개발했습니다. 
> 팀원들에게는 기능 단위로 나누어 비교적 독립적으로 처리할 수 있는 작업을 할당했고, 
> 일정이나 기술적인 부분에서 어려움을 겪는 경우에는 제가 맡은 업무를 마무리한 뒤 팀원들을 서포트하며 함께 해결해나갔습니다.
> 이런 방식으로 팀원들의 부담을 최소화하고 전체 일정에 차질이 생기지 않도록 조율하면서 프로젝트를 완성할 수 있었습니다.

### 🎯 5차 꼬리 질문
개발 리드 역할을 하셨다고 했는데, 혹시 그 과정에서 기술적인 의사결정(예: 아키텍처, 기술스택, 라이브러리 선택 등)을 해야 했던 상황이 있었나요?   
있었다면 어떤 기준으로 결정하셨고, 팀원들의 의견은 어떻게 반영하셨는지도 궁금합니다.
> 사실 이번 프로젝트에서는 기술 스택이나 아키텍처 관련된 큰 의사결정은 기존 시스템이 이미 어느 정도 정해져 있었기 때문에 새롭게 결정할 일은 많지 않았습니다.
> 다만, 개발 리드로서 팀원들과 함께 더 나은 방향을 찾기 위해 각자의 의견을 듣고, 
> 기술적인 이슈가 생겼을 때는 함께 디버깅하거나, 
> 성능상 최적인 방식을 고민해보는 방식으로 의사소통하며 진행했습니다.
> 예를 들어 어떤 기능을 구현할 때 A 방식과 B 방식 중 무엇이 나을지 내부에서 잠깐 토론을 하기도 했고, 
> 그 과정에서 저보다 해당 부분에 익숙한 팀원의 의견을 적극 반영했던 적도 있습니다.
> 아직 큰 규모의 기술 의사결정을 직접 주도해본 경험은 없지만, 
> 만약 그런 기회가 온다면 팀원들과 함께 방향을 논의하고, 
> 실무와 성능, 유지보수 측면을 고려해 균형 있게 판단할 수 있도록 노력할 생각입니다.

---

# 🌱 성장/마인드셋 관련 질문
## 1번 질문
꽤 오랜 기간 다양한 기술을 다루셨는데, 최근에 새롭게 학습한 기술이나 도구가 있다면?    
그걸 어떤 계기로, 어떻게 적용하셨는지 궁금합니다.
> 최근에 새롭게 접한 기술은 Kotlin과 Python입니다.
> 그중 Kotlin은 회사 입사 당시부터 Kafka 관련 로직에 이미 도입되어 있었고, 
> 해당 프로젝트를 맡으면서 처음 사용하게 되었습니다.
> Kotlin은 Java 기반 언어이기 때문에 진입 장벽이 크지는 않았지만, 
> Java보다 함수 호출이 간결하고 코드가 가벼워서 실무에서는 꽤 편리하다고 느꼈습니다.
> 다만 불편했던 점은 Kotlin 관련 레퍼런스 문서가 Java에 비해 상대적으로 적고, 
> 실제로는 Java 문서를 보면서 코드를 Kotlin으로 변환해가며 구현해야 하는 경우가 많았습니다.
> 이 부분은 개발 속도를 다소 저하시킬 수 있었지만, Gradle 플러그인이나 IDE 자동 변환 기능을 적극적으로 활용하면서 극복했습니다.

### 🎯 1차 꼬리 질문
Kotlin을 처음 사용할 때 가장 헷갈리거나 어려웠던 부분은 무엇이었나요? 그리고 어떻게 해결하셨나요?
> Kotlin을 처음 사용할 때는 문법이 Java와 많이 달라서 다소 헷갈렸습니다. 
> 예를 들어 세미콜론을 생략할 수 있다거나, fun 키워드처럼 함수 선언 방식이 훨씬 간결해져서 처음엔 마치 스크립트 언어를 쓰는 듯한 느낌이 들었습니다.
> 이런 부분은 기존의 Java 스타일에 익숙했던 제게 생소했지만, 반복적으로 작성하고 손에 익히는 방식으로 극복했습니다.
> 특히 실무 코드에서 직접 Kotlin으로 Kafka 로직을 다루다 보니 자연스럽게 익숙해질 수 있었습니다.

### 🎯 2차 꼬리 질문
Python을 데이터 마이그레이션 프로젝트에서 처음 사용하셨다고 하셨는데,   
어떤 작업에 사용되었고, Python을 선택한 이유는 무엇이었나요?
> Python은 제가 직접 선택한 언어는 아니고, 입사 당시 해당 프로젝트에 이미 Python이 사용되고 있었기 때문에 자연스럽게 사용하게 되었습니다.
> 다만 Python이 데이터 처리와 스크립트 작업에 강점이 있다는 건 알고 있었고, 
> 실제로도 데이터 마이그레이션이라는 업무 성격상 타사 솔루션에서 받은 회원, 상품, 주문, 게시판 등 다양한 데이터를 
> 자사 DB 형식에 맞게 정제하고 삽입하는 작업에 Python이 잘 맞는다고 느꼈습니다.
> 그래서 Python이 사용된 이유에 대해 공감하면서 학습하고 업무에 적용해볼 수 있었습니다.

### 🎯 3차 꼬리 질문
처음 Python을 사용하시면서 가장 적응이 어려웠던 부분은 무엇이었고, 어떻게 극복하셨나요?
> Python을 처음 사용할 때 가장 낯설었던 점은 코드의 블록을 세미콜론이 아닌 들여쓰기(indentation) 로 구분한다는 점이었습니다.
> 특히 제가 맡은 업무에서는 코틀린, 파이썬, PHP를 동시에 사용해야 하는 상황이 많았기 때문에, 
> 초반에는 언어별 문법 차이 때문에 실수하는 경우가 종종 있었습니다. 
> 예를 들면 세미콜론을 빼먹거나, 파이썬에 세미콜론을 붙이는 식의 혼동이 있었죠.
> 하지만 시간이 지나면서 점점 손에 익었고, 각 언어의 문법과 스타일에 자연스럽게 적응할 수 있었습니다.
 
### 🎯 4차 꼬리 질문
다양한 언어를 동시에 사용하는 업무 환경에서, 유지보수나 코드 일관성을 위해 특별히 신경 썼던 부분이 있을까요?
> 다양한 언어를 동시에 사용하는 환경에서는 코드의 재사용성과 네이밍 룰에 가장 신경을 많이 썼습니다.
> 특히 변수명이나 함수명을 명확하게 지으려고 노력했는데요, 
> 그 이유는 추후에 유지보수를 진행할 때 역할이 명확하지 않은 네이밍은 이해하는 데 시간이 오래 걸리거나 실수를 유발할 수 있기 때문입니다.
> 또, 코드가 레거시로 남게 되는 경우는 대부분 재사용성과 가독성을 고려하지 않고 작성되었을 때라고 생각해서, 되도록 범용적으로 쓸 수 있도록 함수 단위를 나누고, 역할 기반으로 구조화하려고 했습니다.

## 2번 질문
경력 10년차 개발자로서, 지금 스스로 가장 강점이라고 생각하는 기술/역량과, 여전히 개선하고 싶은 점은 어떤 것인가요?
> 제 강점은 기획자 및 현업과의 커뮤니케이션 능력입니다. 
> 단순히 주어진 업무를 처리하는 데 그치지 않고, 소통 과정에서 더 나은 방향을 도출해내는 데에 익숙합니다.
> 실제로 기획 단계가 완전히 마무리되지 않은 프로젝트에서 기획과 개발을 병행하며 방향을 잡아간 경험도 있고, 
> 개발 중 기술적인 제약이 발생했을 때 기획자와 적절한 대안을 조율해온 경험도 많습니다.
> 반면에 약점은 특정 언어 하나를 오랜 기간 깊게 파기보다는,
> 다양한 언어(PHP, Java, Kotlin, Python 등)를 프로젝트에 맞게 사용해왔기 때문에 언어에 대한 깊은 전문성 면에서는 아쉬울 수 있다고 생각합니다.
> 하지만 덕분에 새로운 언어, 새로운 환경에도 빠르게 적응할 수 있게 되었고, 
> 다양한 시스템을 연결하거나 이질적인 팀들과 협업하는 데에는 오히려 유연성이 강점이 되었다고 생각합니다.

---
# 💧 전직장 퇴사 이유?
> 전 직장에서는 주로 독립적으로 맡은 업무를 수행하는 경우가 많았고, 
> 기획팀과 긴밀하게 협의하며 함께 방향을 잡아가는 방식보다는 기획팀의 요청사항을 그대로 처리하는 형태가 많았습니다.
> 저는 제 강점이 기획자 및 현업과의 커뮤니케이션이라고 생각하고 있고, 
> 실제로 소통을 통해 더 좋은 결과물을 도출하는 과정에서 동기를 많이 느끼는 편입니다.
> 그래서 저의 강점을 더 잘 발휘하고, 협업 중심의 환경에서 함께 성장할 수 있는 기회를 찾고자 이직을 결심하게 되었습니다.

## 1번 질문
전 직장에서 독립적인 업무가 많았다고 하셨는데, 그렇다면 그곳에서 협력하는 기회가 전혀 없었나요?   
혹시 협업을 강화하기 위한 노력을 하지 않으셨나요?
> 협업을 시도했으나 구조적으로나 문화적으로 협업이 어려웠다는 점을 부드럽게 설명하는 것이 중요합니다.

## 2번 질문
그렇다면 협업의 기회를 늘리기 위해 어떤 방식으로 기획자나 개발자와 소통하려고 시도했나요?   
예를 들어, 소통 채널을 더 적극적으로 활용했거나, 자주 미팅을 주도하려는 노력을 하지 않으셨나요?
> 이 질문에 대해서는 적극적으로 소통을 시도했으나, 그 시도가 원하는 결과를 얻지 못했다고 말할 수 있습니다. 
> 예를 들어, "정기적인 미팅을 제안하거나, 의견을 나누기 위해 노력을 했지만, 조직의 업무 문화나 환경상 한계가 있었다"고 솔직하게 설명하고, 
> 그럼에도 불구하고 협업의 중요성을 깨닫고 더 넓은 협업 환경에서 일하고자 결심했다는 점을 강조하는 것이 좋습니다.

## 3번 질문
그럼에도 불구하고 퇴사 후 휴식을 취하고 싶다고 하셨는데,   
이는 단순히 잠시 쉬고 싶다는 것 외에 향후 커리어 방향에 대해 어떤 고민이 있었던 건가요?
> 9년간의 지속적인 경력을 통해 많은 것을 배웠고, 이제는 좀 더 전략적으로 커리어를 계획하고 싶었습니다. 
> 긴 시간 동안 일을 해왔기 때문에 잠시 쉬면서 제 자신의 업무 스타일과 방향성에 대해 다시 한번 고민하고 싶었고, 
> 이를 통해 좀 더 발전할 수 있을 것이라 생각했고 제 경험을 더 잘 활용할 수 있는 직장을 찾고 있습니다.

### 💬 쿠팡이츠를 선택한 이유는 무엇인가요?
> 전 직장에서 마녀공장의 네고왕 이벤트를 진행할 때, 
> 순간적으로 8만 명 이상의 사용자가 몰리면서 대규모 트래픽을 직접 체감한 적이 있었습니다. 
> 당시 제 역할은 넷퍼넬을 통해 트래픽을 제어하는 작업이었지만,
> 그 경험을 계기로 '이런 대규모 트래픽은 어떻게 안정적으로 처리될까?'에 대해 큰 호기심이 생겼습니다.
> 쿠팡이츠는 현재 굉장히 빠르게 성장하고 있는 서비스이고, 
> 제가 경험했던 것보다 훨씬 더 큰 트래픽과 복잡한 시스템이 운영되는 환경이라고 생각했습니다.
> 이 안에서 일한다면, 제가 가진 경험을 더 확장하고, 기술적으로 더 성장할 수 있겠다는 확신이 들어 지원하게 되었습니다. 

### 💬 가장 기억에 남는 버그나 장애 경험은?
> 최근에 진행한 Kafka 기반 상점 이미지 클라우드 업로드 프로젝트가 가장 기억에 남습니다.
> 배포 초기, 로직 조건이 잘못되어 무한 리트라이가 발생했고, 이로 인해 밤새 메신저가 울렸습니다.
> 새벽에 급히 로직을 점검하고 핫픽스를 배포했는데, 다행히 사용자에게 영향은 가지 않았습니다.
> 식은땀이 났지만, 이런 긴장감 속에서도 문제를 해결해나가는 과정이 재밌고, 그래서 개발자를 계속하고 있는 것 같습니다.

### 💬 스트레스는 어떻게 관리하나요?
> 저는 스트레스를 오래 품고 있지 않는 성격입니다.
> 집에서 맛있는 걸 먹고 푹 자면 대부분 해결되고, 그래도 남아 있다면 주말에 등산을 하며 땀을 흘리면 기분이 확 좋아집니다.

### 💬 업무 외 도와줬던 경험이 있다면?
> 기획팀에서 개발적인 내용을 바탕으로 메일이나 메시지를 작성할 때, 제가 해당 내용을 검토해주는 경우가 많았습니다.
> 기술적인 내용을 이해하기 쉽게 풀어주는 걸 좋아하기도 하고, 이런 협업이 즐겁습니다.

### 💬 요즘 관심 있는 기술/트렌드는?
> "대규모 트래픽 처리"에 관심이 많습니다.
> 트래픽이 집중되는 서비스는 어떻게 서버 아키텍처를 구성하고, 어떤 방식으로 로직을 구성했는지가 항상 궁금하고 흥미롭습니다.

### 💬 쿠팡이츠에 입사한다면 어떻게 기여하고 싶나요?
> 저의 강점은 커뮤니케이션 능력과 빠른 적응력입니다.
> 어떤 환경에서든 빠르게 팀에 스며들 수 있고, 협업을 통해 더 나은 결과를 도출할 수 있다고 믿습니다.
> 그런 방식으로 팀과 서비스에 기여하고 싶습니다.

---

# ✅ 마지막 하고 싶은 말
> 제가 가진 가장 큰 강점은 문제 해결을 위한 커뮤니케이션 능력이라고 생각합니다.
> 다양한 언어와 프로젝트를 경험하며 빠르게 적응하는 법도 익혔고,
> 기술적인 역량뿐만 아니라 팀과 함께 일하는 방식에 대해 고민하고 실천하는 개발자입니다.
> 기회가 주어진다면, 쿠팡이츠에서 의미 있는 성장을 함께 만들어가고 싶습니다. 감사합니다.